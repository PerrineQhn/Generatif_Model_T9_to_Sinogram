{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1c406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/perrineqhn/Desktop/M2/S2/Méthode en Apprentissage Automatique/tf_metal_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/perrineqhn/.cache/kagglehub/datasets/noxmoon/chinese-official-daily-news-since-2016/versions/1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import kagglehub\n",
    "import keras\n",
    "import keras_hub\n",
    "import keras_tuner\n",
    "import pandas as pd\n",
    "import pkuseg\n",
    "import tensorflow as tf\n",
    "from datasets import Dataset\n",
    "from pypinyin import lazy_pinyin\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM,\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    Input,\n",
    "    StringLookup,\n",
    "    TextVectorization,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "path = kagglehub.dataset_download(\"noxmoon/chinese-official-daily-news-since-2016\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b3e85f",
   "metadata": {},
   "source": [
    "# Création du corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1de02ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20738 entries, 0 to 20737\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   date      20738 non-null  object\n",
      " 1   tag       20738 non-null  object\n",
      " 2   headline  20738 non-null  object\n",
      " 3   content   20631 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 648.2+ KB\n",
      "None\n",
      "Dataset head:\n",
      "         date   tag                                           headline  \\\n",
      "0  2016-01-01  详细全文  陆军领导机构火箭军战略支援部队成立大会在京举行 习近平向中国人民解放军陆军火箭军战略支援部队...   \n",
      "1  2016-01-01  详细全文                             中央军委印发《关于深化国防和军队改革的意见》   \n",
      "2  2016-01-01  详细全文                           《习近平关于严明党的纪律和规矩论述摘编》出版发行   \n",
      "3  2016-01-01  详细全文                                 以实际行动向党中央看齐 向高标准努力   \n",
      "4  2016-01-01  详细全文                                 【年终特稿】关键之年 改革挺进深水区   \n",
      "\n",
      "                                             content  \n",
      "0  中国人民解放军陆军领导机构、中国人民解放军火箭军、中国人民解放军战略支援部队成立大会2015...  \n",
      "1  经中央军委主席习近平批准，中央军委近日印发了《关于深化国防和军队改革的意见》。\\n《意见》强...  \n",
      "2  由中共中央纪律检查委员会、中共中央文献研究室编辑的《习近平关于严明党的纪律和规矩论述摘编》一...  \n",
      "3  广大党员干部正在积极学习习近平总书记在中央政治局专题民主生活会上的重要讲话。大家纷纷表示要把...  \n",
      "4  刚刚过去的2015年，是全面深化改革的关键之年。改革集中发力在制约经济社会发展的深层次矛盾，...  \n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(path+\"/chinese_news.csv\")\n",
    "# Print dataset information\n",
    "print(\"Dataset information:\")\n",
    "print(dataset.info())\n",
    "# Print dataset head\n",
    "print(\"Dataset head:\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef64267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after preprocessing:\n",
      "                                             content  \\\n",
      "0  中国人民解放军陆军领导机构、中国人民解放军火箭军、中国人民解放军战略支援部队成立大会2015...   \n",
      "1  经中央军委主席习近平批准，中央军委近日印发了《关于深化国防和军队改革的意见》。\\n《意见》强...   \n",
      "2  由中共中央纪律检查委员会、中共中央文献研究室编辑的《习近平关于严明党的纪律和规矩论述摘编》一...   \n",
      "3  广大党员干部正在积极学习习近平总书记在中央政治局专题民主生活会上的重要讲话。大家纷纷表示要把...   \n",
      "4  刚刚过去的2015年，是全面深化改革的关键之年。改革集中发力在制约经济社会发展的深层次矛盾，...   \n",
      "\n",
      "                                     cleaned_content  \n",
      "0  中国人民解放军陆军领导机构、中国人民解放军火箭军、中国人民解放军战略支援部队成立大会年月日在...  \n",
      "1  经中央军委主席习近平批准，中央军委近日印发了《关于深化国防和军队改革的意见》。《意见》强调，...  \n",
      "2  由中共中央纪律检查委员会、中共中央文献研究室编辑的《习近平关于严明党的纪律和规矩论述摘编》一...  \n",
      "3  广大党员干部正在积极学习习近平总书记在中央政治局专题民主生活会上的重要讲话。大家纷纷表示要把...  \n",
      "4  刚刚过去的年，是全面深化改革的关键之年。改革集中发力在制约经济社会发展的深层次矛盾，集中发力...  \n",
      "0    [中国, 人民, 解放军, 陆军, 领导, 机构, 、, 中国, 人民, 解放军, 火箭军,...\n",
      "1    [经, 中央军委, 主席, 习近平, 批准, ，, 中央军委, 近日, 印发, 了, 《, ...\n",
      "2    [由, 中共中央, 纪律, 检查, 委员会, 、, 中共中央, 文献, 研究室, 编辑, 的...\n",
      "3    [广大, 党员, 干部, 正在, 积极, 学习, 习近平, 总书记, 在, 中央, 政治局,...\n",
      "4    [刚刚, 过去, 的, 年, ，, 是, 全面, 深化, 改革, 的, 关键, 之, 年, ...\n",
      "Name: tokens, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Prétraitement de content (suppression des caractères non chinois, normalisation des espaces)\n",
    "def clean_content(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Garder les caractères chinois et ponctuation chinoise\n",
    "    text = re.sub(r\"[^\\u4e00-\\u9fff\\u3000-\\u303F\\uff00-\\uffef]\", \"\", text)\n",
    "    \n",
    "    # Normaliser les espaces (rare, mais au cas où)\n",
    "    text = text.replace(\" \", \"\").strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Appliquer le prétraitement à la colonne 'content'\n",
    "dataset['cleaned_content'] = dataset['content'].apply(clean_content)\n",
    "\n",
    "# Afficher les 5 premières lignes du DataFrame après le prétraitement\n",
    "print(\"Dataset after preprocessing:\")\n",
    "print(dataset[['content', 'cleaned_content']].head())\n",
    "\n",
    "seg = pkuseg.pkuseg()\n",
    "dataset[\"tokens\"] = dataset[\"cleaned_content\"].apply(lambda x: seg.cut(x))\n",
    "\n",
    "# Aperçu\n",
    "print(dataset[\"tokens\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add6bdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after generating sequences:\n",
      "                                             content  \\\n",
      "0  中国人民解放军陆军领导机构、中国人民解放军火箭军、中国人民解放军战略支援部队成立大会2015...   \n",
      "1  经中央军委主席习近平批准，中央军委近日印发了《关于深化国防和军队改革的意见》。\\n《意见》强...   \n",
      "2  由中共中央纪律检查委员会、中共中央文献研究室编辑的《习近平关于严明党的纪律和规矩论述摘编》一...   \n",
      "3  广大党员干部正在积极学习习近平总书记在中央政治局专题民主生活会上的重要讲话。大家纷纷表示要把...   \n",
      "4  刚刚过去的2015年，是全面深化改革的关键之年。改革集中发力在制约经济社会发展的深层次矛盾，...   \n",
      "\n",
      "                             char_pinyin_t9_sequence  \n",
      "0  中|zhong|94664 国|guo|486 人|ren|736 民|min|646 解|...  \n",
      "1  经|jing|5464 中|zhong|94664 央|yang|9264 军|jun|58...  \n",
      "2  由|you|968 中|zhong|94664 共|gong|4664 中|zhong|94...  \n",
      "3  广|guang|48264 大|da|32 党|dang|3264 员|yuan|9826 ...  \n",
      "4  刚|gang|4264 刚|gang|4264 过|guo|486 去|qu|78 的|de...  \n"
     ]
    }
   ],
   "source": [
    "# convert the content column to pinyin\n",
    "t9_map = {\n",
    "    \"@\": \"1\", \".\": \"1\", \":\": \"1\",\n",
    "    \"a\": \"2\", \"b\": \"2\", \"c\": \"2\",\n",
    "    \"d\": \"3\", \"e\": \"3\", \"f\": \"3\",\n",
    "    \"g\": \"4\", \"h\": \"4\", \"i\": \"4\",\n",
    "    \"j\": \"5\", \"k\": \"5\", \"l\": \"5\",\n",
    "    \"m\": \"6\", \"n\": \"6\", \"o\": \"6\",\n",
    "    \"p\": \"7\", \"q\": \"7\", \"r\": \"7\", \"s\": \"7\",\n",
    "    \"t\": \"8\", \"u\": \"8\", \"v\": \"8\",\n",
    "    \"w\": \"9\", \"x\": \"9\", \"y\": \"9\", \"z\": \"9\",\n",
    "    \"1\": \"1\", \"2\": \"2\", \"3\": \"3\", \"4\": \"4\",\n",
    "    \"5\": \"5\", \"6\": \"6\", \"7\": \"7\", \"8\": \"8\",\n",
    "    \"9\": \"9\", \"0\": \"0\", \" \": \"0\",\n",
    "    \"。\":\"。\", \"，\":\"，\", \"？\":\"？\", \"！\":\"！\",\n",
    "}\n",
    "\n",
    "# Fonction pour convertir une chaîne de caractères en code T9\n",
    "def pinyin_to_t9(text):\n",
    "    t9_code = \"\"\n",
    "    # print(text)\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    for char in text:\n",
    "        if char.lower() in t9_map:\n",
    "            t9_code += t9_map[char.lower()]\n",
    "        else:\n",
    "            t9_code += char  # Conserver les caractères non mappés tels quels\n",
    "    return t9_code\n",
    "\n",
    "def generer_sequence_contextuelle(row):\n",
    "    tokens = eval(row[\"tokens\"]) if isinstance(row[\"tokens\"], str) else row[\"tokens\"]\n",
    "    sequence = []\n",
    "    for token in tokens:\n",
    "        if not isinstance(token, str) or not re.search(r'[\\u4e00-\\u9fff]', token):\n",
    "            continue\n",
    "        for char, py in zip(token, lazy_pinyin(token)):\n",
    "            t9 = pinyin_to_t9(py)\n",
    "            sequence.append(f\"{char}|{py}|{t9}\")\n",
    "    return ' '.join(sequence)\n",
    "\n",
    "dataset[\"char_pinyin_t9_sequence\"] = dataset.apply(generer_sequence_contextuelle, axis=1)\n",
    "\n",
    "# Sauvegarder le fichier\n",
    "dataset[[\"char_pinyin_t9_sequence\"]].to_csv(\"sequences_char_pinyin_t9.csv\", index=False)\n",
    "\n",
    "# Afficher les 5 premières lignes du DataFrame après le prétraitement\n",
    "print(\"Dataset after generating sequences:\")\n",
    "print(dataset[['content', 'char_pinyin_t9_sequence']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc41c160",
   "metadata": {},
   "source": [
    "# Création du dataset pour le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9336abca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer en séquences complètes\n",
    "input_t9_sequences = []\n",
    "target_char_sequences = []\n",
    "\n",
    "for seq in dataset[\"char_pinyin_t9_sequence\"]:\n",
    "    triplets = seq.strip().split(\" \")\n",
    "    t9_seq = []\n",
    "    char_seq = []\n",
    "    \n",
    "    # Extraire les paires char|T9 pour chaque phrase\n",
    "    for triplet in triplets:\n",
    "        parts = triplet.split(\"|\")\n",
    "        if len(parts) == 3:\n",
    "            char, _, t9 = parts\n",
    "            char_seq.append(char)\n",
    "            t9_seq.append(t9)\n",
    "    # Ajouter les séquences T9 et caractères\n",
    "    input_t9_sequences.append(\" \".join(t9_seq))\n",
    "    # Ajouter <START> et <END> directement dans les données\n",
    "    target_char_sequences.append(\"<START> \" + \" \".join(char_seq) + \" <END>\")\n",
    "\n",
    "# Créer un DataFrame\n",
    "df_sequences = pd.DataFrame({\n",
    "    \"input_t9_sequence\": input_t9_sequences,\n",
    "    \"target_char_sequence\": target_char_sequences\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f096bbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame sequences:\n",
      "                                   input_t9_sequence  \\\n",
      "0  94664 486 736 646 543 3264 586 58 586 5464 326...   \n",
      "1  5464 94664 9264 586 934 948 94 94 546 7464 74 ...   \n",
      "2  968 94664 4664 94664 9264 54 58 5426 242 934 9...   \n",
      "3  48264 32 3264 9826 426 28 94364 924 54 54 983 ...   \n",
      "4  4264 4264 486 78 33 6426 744 7826 6426 7436 48...   \n",
      "\n",
      "                                target_char_sequence  \n",
      "0  <START> 中 国 人 民 解 放 军 陆 军 领 导 机 构 中 国 人 民 解 放 ...  \n",
      "1  <START> 经 中 央 军 委 主 席 习 近 平 批 准 中 央 军 委 近 日 印 ...  \n",
      "2  <START> 由 中 共 中 央 纪 律 检 查 委 员 会 中 共 中 央 文 献 研 ...  \n",
      "3  <START> 广 大 党 员 干 部 正 在 积 极 学 习 习 近 平 总 书 记 在 ...  \n",
      "4  <START> 刚 刚 过 去 的 年 是 全 面 深 化 改 革 的 关 键 之 年 改 ...  \n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame sequences:\")\n",
    "print(df_sequences.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6434642",
   "metadata": {},
   "source": [
    "## Encoder les données pour Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e326d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31149a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf779c5f",
   "metadata": {},
   "source": [
    "## Split train-valid-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec477403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "870dabbe",
   "metadata": {},
   "source": [
    "# Modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38f6c70",
   "metadata": {},
   "source": [
    "Sogou T9 est une méthode d’entrée intelligente qui :\n",
    "\n",
    "- Prend des séquences numériques (ex. : \"94664 486\" pour \"zhong guo\").\n",
    "- Génère des séquences de caractères chinois (ex. : \"中国\").\n",
    "- Utilise le contexte (mots précédents) pour désambiguïser les prédictions.\n",
    "- Est optimisé pour la vitesse et la précision, souvent avec des modèles entraînés sur de vastes corpus.\n",
    "\n",
    "Pour reproduire cela, il faut utiliser un modèle seq2seq avec un encodeur-décodeur (2 entrées) :\n",
    "\n",
    "- Encodeur : Lit la séquence T9 et la compresse en une représentation contextuelle.\n",
    "- Décodeur : Génère la séquence de caractères chinois à partir de cette représentation.\n",
    "\n",
    "[Functional API](https://keras.io/guides/functional_api/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e252e198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03663220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec78a4e4",
   "metadata": {},
   "source": [
    "# Génération"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007970b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_metal_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
